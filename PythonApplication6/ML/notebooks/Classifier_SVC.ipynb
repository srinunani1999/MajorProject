{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.6.8 (tags/v3.6.8:3c6b436a57, Dec 24 2018, 00:16:47) [MSC v.1916 64 bit (AMD64)]'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import collections\n",
    "import random \n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_chars(s):\n",
    "    return len(s)\n",
    "\n",
    "def unique_chars(s):\n",
    "    s2 = ''.join(set(s))\n",
    "    return len(s2)\n",
    "\n",
    "def weighted_unique_chars(s):\n",
    "    return unique_chars(s)/number_of_chars(s)\n",
    "\n",
    "def words_count(s):\n",
    "    return collections.Counter(s)\n",
    "\n",
    "def words_counter_object(s):\n",
    "    cnt = collections.Counter()\n",
    "\n",
    "    words = s.split()\n",
    "    for w in words:\n",
    "        cnt[w] += 1\n",
    "\n",
    "    return cnt\n",
    "\n",
    "def total_words(cnt):\n",
    "    sum = 0\n",
    "    for k in dict(cnt).keys():\n",
    "        sum += int(cnt[k])\n",
    "\n",
    "    return sum\n",
    "\n",
    "def is_repeated(cnt):\n",
    "    for k,v in cnt.most_common(1):\n",
    "        freq = v/total_words(cnt)\n",
    "        if freq > 0.5:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def discrete_label(target_value):\n",
    "    if target_value != float(1):\n",
    "        target_value = 0\n",
    "    return target_value\n",
    "\n",
    "def make_feature_vector(critique, labels):\n",
    "    \" construct feature vector\" \n",
    "    feature_vector = []\n",
    "    for i in range(len(critique)):\n",
    "        s = critique[i]\n",
    "        feature = []\n",
    "        counter_obj = words_counter_object(s)\n",
    "\n",
    "        feature.append(number_of_chars(s))\n",
    "        feature.append(unique_chars(s))\n",
    "        feature.append(weighted_unique_chars(s))\n",
    "        feature.append(total_words(counter_obj))\n",
    "        feature.append(is_repeated(counter_obj))\n",
    "\n",
    "        feature.append(discrete_label(labels[i]))\n",
    "        feature_vector.append(feature)\n",
    "\n",
    "    return feature_vector\n",
    "\n",
    "def read_data():\n",
    "    ''' read and make a list of critiques'''\n",
    "    df = pd.read_csv('../data/Evaluations-Binary.csv')\n",
    "    critiques,labels = df['Review'].tolist(), df['Useful'].tolist()\n",
    "    return critiques,labels\n",
    "\n",
    "def make_np_array_XY(xy):\n",
    "    a = np.array(xy)\n",
    "    x = a[:,0:-1]\n",
    "    y = a[:,-1]\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Got 116 out of 157\n",
      "accuracy: 0.7388535031847133\n",
      "f1 macro = 0.45\n",
      "f1 micro = 0.74\n",
      "f1 weighted = 0.63\n"
     ]
    }
   ],
   "source": [
    "critiques, labels = read_data()\n",
    "features_and_labels = make_feature_vector(critiques, labels)\n",
    "number_of_features = len(features_and_labels[0]) - 1\n",
    "random.shuffle(features_and_labels)\n",
    "\n",
    "mid_index = int(len(features_and_labels)/2)\n",
    "XY_train = features_and_labels[:mid_index]\n",
    "XY_test = features_and_labels[mid_index:]\n",
    "\n",
    "X_train, Y_train = make_np_array_XY(XY_train)\n",
    "\n",
    "X_test, Y_test = make_np_array_XY(XY_test)\n",
    "\n",
    "C = 1.0  # SVM regularization parameter\n",
    "svc = svm.SVC(kernel='linear', C=C).fit(X_train, Y_train)\n",
    "\n",
    "Y_predict = svc.predict(X_test)\n",
    "\n",
    "print(Y_predict)\n",
    "\n",
    "#metrics\n",
    "test_size = len(Y_test)\n",
    "score = 0\n",
    "for i in range(test_size):\n",
    "    if Y_predict[i] == Y_test[i]:\n",
    "        score += 1\n",
    "\n",
    "\n",
    "print('Got %s out of %s' %(score, test_size))\n",
    "\n",
    "print('accuracy: %s' %(score/test_size))\n",
    "\n",
    "# f1 score\n",
    "f1 = f1_score(Y_test, Y_predict, average='macro')  \n",
    "print('f1 macro = %.2f' %(f1))\n",
    "f1 = f1_score(Y_test, Y_predict, average='micro')  \n",
    "print('f1 micro = %.2f' %(f1))\n",
    "f1 = f1_score(Y_test, Y_predict, average='weighted')  \n",
    "print('f1 weighted = %.2f' %(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
